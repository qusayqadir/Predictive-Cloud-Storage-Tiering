{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling - Determining AWS S3 Storage Tier\n",
    "\n",
    "Use the syenthetic data to build model(s) that predicits the storage tier of new files. \n",
    "To efficiently and correctly catergorize files into different storage tiers is useful becuase it allows for cost optimization, storage efficiency, and client performance optimization: retrivel times "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS S3 Tiers \n",
    "\n",
    "The model(s) built will analyze the metadata of the file to store it in one of three storage classes\n",
    "\n",
    "Overview of the storage classses in use: \n",
    "\n",
    "<table align=\"left\" style=\"width:50%\"> \n",
    "    <tr>\n",
    "        <th>Class</th>\n",
    "        <th>Use Case</th>\n",
    "        <th>Tier</th> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>S3 Standard</td>\n",
    "        <td>Frequently Accessed</td>\n",
    "        <td>\"Hot\"</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>S3 One Zone-IA</td>\n",
    "        <td>Infrequent, low-availability data </td>\n",
    "        <td>\"Warm\"</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>S3 Glacier (Deep Archieve?)</td>\n",
    "        <td>Rarely Accessed / Long-term rarely accessed</td>\n",
    "        <td>\"Cold\"</td>\n",
    "    </tr>\n",
    "</table> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Data Preperation - preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible approaches towards a dataset preprocessing before fitting it a model \n",
    "\n",
    "**1)** Handle missing/null values \n",
    "\n",
    "**2)** Normalize/scale numerical features \n",
    "\n",
    "Standardization: Scale values to have a mean of 0 and standard deviation of 1.\n",
    "\n",
    "Normalization: Rescale values to fall within a range (e.g., 0â€“1).\n",
    "\n",
    "**3)** Encode categorical features : ordinal encoding ( hot > warm > cold)\n",
    "\n",
    "**4)** Feature engineering + Class imbalance ( create/remove columns ) \n",
    "\n",
    "New rows for edge cases to help the model learn critical boundries,\n",
    "\n",
    "Talk about not dropping access_frequency and frequency of access.  \n",
    "\n",
    "need to determine if the target variable 'Storage_Tier' in the dataset is balanced, risk the model becoming biased  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_ID</th>\n",
       "      <th>Access_Frequency</th>\n",
       "      <th>Frequnecy_of_Access</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>File_Lifecycle_Stage</th>\n",
       "      <th>Modification_Frequency</th>\n",
       "      <th>File_Age</th>\n",
       "      <th>Storage_Tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>File_1</td>\n",
       "      <td>21.2307</td>\n",
       "      <td>24.4205</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23.3177</td>\n",
       "      <td>2.6015</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>File_2</td>\n",
       "      <td>24.0589</td>\n",
       "      <td>4.5884</td>\n",
       "      <td>1.8784</td>\n",
       "      <td>8.4383</td>\n",
       "      <td>4.8516</td>\n",
       "      <td>7.7843</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>File_3</td>\n",
       "      <td>25.1752</td>\n",
       "      <td>10.1110</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.7295</td>\n",
       "      <td>1.9126</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>File_4</td>\n",
       "      <td>4.2926</td>\n",
       "      <td>17.4557</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.7832</td>\n",
       "      <td>2.3784</td>\n",
       "      <td>Cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>File_5</td>\n",
       "      <td>19.9357</td>\n",
       "      <td>23.3908</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.2302</td>\n",
       "      <td>3.5120</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>File_6</td>\n",
       "      <td>28.4249</td>\n",
       "      <td>23.1148</td>\n",
       "      <td>7.0560</td>\n",
       "      <td>9.1548</td>\n",
       "      <td>9.2075</td>\n",
       "      <td>1.8900</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>File_7</td>\n",
       "      <td>19.6673</td>\n",
       "      <td>8.6535</td>\n",
       "      <td>6.2278</td>\n",
       "      <td>7.9220</td>\n",
       "      <td>14.8424</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>File_8</td>\n",
       "      <td>16.5561</td>\n",
       "      <td>22.7516</td>\n",
       "      <td>4.0345</td>\n",
       "      <td>3.5290</td>\n",
       "      <td>9.6637</td>\n",
       "      <td>5.4443</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>File_9</td>\n",
       "      <td>9.0017</td>\n",
       "      <td>8.5943</td>\n",
       "      <td>15.8221</td>\n",
       "      <td>15.2384</td>\n",
       "      <td>9.1963</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>File_10</td>\n",
       "      <td>17.6529</td>\n",
       "      <td>18.1427</td>\n",
       "      <td>10.5044</td>\n",
       "      <td>4.3349</td>\n",
       "      <td>4.9068</td>\n",
       "      <td>5.5250</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File_ID  Access_Frequency  Frequnecy_of_Access  File_Size  \\\n",
       "0   File_1           21.2307              24.4205     0.0000   \n",
       "1   File_2           24.0589               4.5884     1.8784   \n",
       "2   File_3           25.1752              10.1110     0.0000   \n",
       "3   File_4            4.2926              17.4557     0.0000   \n",
       "4   File_5           19.9357              23.3908     0.0000   \n",
       "5   File_6           28.4249              23.1148     7.0560   \n",
       "6   File_7           19.6673               8.6535     6.2278   \n",
       "7   File_8           16.5561              22.7516     4.0345   \n",
       "8   File_9            9.0017               8.5943    15.8221   \n",
       "9  File_10           17.6529              18.1427    10.5044   \n",
       "\n",
       "   File_Lifecycle_Stage  Modification_Frequency  File_Age Storage_Tier  \n",
       "0                0.0000                 23.3177    2.6015          Hot  \n",
       "1                8.4383                  4.8516    7.7843         Warm  \n",
       "2                0.0000                  5.7295    1.9126         Warm  \n",
       "3                0.0000                  8.7832    2.3784         Cold  \n",
       "4                0.0000                 12.2302    3.5120         Warm  \n",
       "5                9.1548                  9.2075    1.8900          Hot  \n",
       "6                7.9220                 14.8424    0.0000         Warm  \n",
       "7                3.5290                  9.6637    5.4443         Warm  \n",
       "8               15.2384                  9.1963    0.0000         Warm  \n",
       "9                4.3349                  4.9068    5.5250         Warm  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "np.random.seed(1)  \n",
    "\n",
    "df = pd.read_csv(\"../../data/train-model/train-file-metadata.csv\") \n",
    "\n",
    "df.head(n=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   File_ID                 2000 non-null   object \n",
      " 1   Access_Frequency        2000 non-null   float64\n",
      " 2   Frequnecy_of_Access     2000 non-null   float64\n",
      " 3   File_Size               2000 non-null   float64\n",
      " 4   File_Lifecycle_Stage    2000 non-null   float64\n",
      " 5   Modification_Frequency  2000 non-null   float64\n",
      " 6   File_Age                2000 non-null   float64\n",
      " 7   Storage_Tier            2000 non-null   object \n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 125.1+ KB\n",
      "None\n",
      "['Hot' 'Warm' 'Cold']\n",
      "(2000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Access_Frequency</th>\n",
       "      <th>Frequnecy_of_Access</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>File_Lifecycle_Stage</th>\n",
       "      <th>Modification_Frequency</th>\n",
       "      <th>File_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.515501</td>\n",
       "      <td>12.030583</td>\n",
       "      <td>7.976287</td>\n",
       "      <td>5.460082</td>\n",
       "      <td>10.834073</td>\n",
       "      <td>2.669299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.291801</td>\n",
       "      <td>7.569856</td>\n",
       "      <td>8.205440</td>\n",
       "      <td>5.579764</td>\n",
       "      <td>6.968456</td>\n",
       "      <td>2.702448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.077500</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.705800</td>\n",
       "      <td>5.658150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.471100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.539200</td>\n",
       "      <td>9.676650</td>\n",
       "      <td>6.135600</td>\n",
       "      <td>4.304750</td>\n",
       "      <td>8.902350</td>\n",
       "      <td>2.147300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.577300</td>\n",
       "      <td>18.057800</td>\n",
       "      <td>13.035925</td>\n",
       "      <td>8.843775</td>\n",
       "      <td>15.534425</td>\n",
       "      <td>4.273350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.595800</td>\n",
       "      <td>29.673700</td>\n",
       "      <td>29.696700</td>\n",
       "      <td>19.798900</td>\n",
       "      <td>29.658500</td>\n",
       "      <td>9.889600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Access_Frequency  Frequnecy_of_Access    File_Size  \\\n",
       "count       2000.000000          2000.000000  2000.000000   \n",
       "mean          15.515501            12.030583     7.976287   \n",
       "std            8.291801             7.569856     8.205440   \n",
       "min            2.077500             1.007200     0.000000   \n",
       "25%            8.705800             5.658150     0.000000   \n",
       "50%           14.539200             9.676650     6.135600   \n",
       "75%           21.577300            18.057800    13.035925   \n",
       "max           34.595800            29.673700    29.696700   \n",
       "\n",
       "       File_Lifecycle_Stage  Modification_Frequency     File_Age  \n",
       "count           2000.000000             2000.000000  2000.000000  \n",
       "mean               5.460082               10.834073     2.669299  \n",
       "std                5.579764                6.968456     2.702448  \n",
       "min                0.000000                1.013700     0.000000  \n",
       "25%                0.000000                5.471100     0.000000  \n",
       "50%                4.304750                8.902350     2.147300  \n",
       "75%                8.843775               15.534425     4.273350  \n",
       "max               19.798900               29.658500     9.889600  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df[\"Storage_Tier\"].unique())\n",
    "print(df.shape) \n",
    "\n",
    "\n",
    "df.isna().sum() # shows that there is a complete dataset no missing or null values \n",
    "df.describe() #  column values needs to be normalized for better model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the description of the dataset shows that the values need to be standardized for all the columns to have a mean of 0 and a standard deviation of 1. also shows evidence for normalizatoin so will need to resacle values to fall under the range 0 - 1\n",
    "\n",
    "the dataset is complete, no handling of missing values that have to be imputed by the mean of certain columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize & Standardize columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why is it important to standardize and normalize the values? \n",
    "\n",
    "standardize helps avoid the features that have larger values from dominating the model and developing a bias and helps bring the values closer to a normal distribution ( i will use visualization tools to check if this is true - seaborn? ). normalizing helps all the features be scaled to the same range most commonly 0 - 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "\n",
    "\n",
    "stand__norm_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "scaler_standard = StandardScaler() \n",
    "scaler_minmaxScaler = MinMaxScaler() \n",
    "\n",
    "df_copy = df.copy() \n",
    "\n",
    "#Standardize\n",
    "standardized_value = scaler_standard.fit_transform(df[stand__norm_columns])\n",
    "for row, col in enumerate(stand__norm_columns): \n",
    "    df_copy[f\"{col}\"] = standardized_value[:, row ]\n",
    "\n",
    " \n",
    "#Normalzie \n",
    "normalized_values = scaler_minmaxScaler.fit_transform(df[stand__norm_columns])\n",
    "for row, col in enumerate(stand__norm_columns): \n",
    "    df_copy[f\"{col}\"] = normalized_values[:, row]\n",
    "\n",
    "df_copy = df_copy.round(4) # higher precision for imporved accuracy \n",
    "\n",
    "np.random.seed(2) \n",
    "\n",
    "output_file = \"preprocessed-train-file-metadata.csv\" \n",
    "df_copy.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, use the 'preprocessed-train-file-metadata.csv' for further preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Categorical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "  File_ID  Access_Frequency  Frequnecy_of_Access  File_Size  \\\n",
      "0  File_1            0.5890               0.8167     0.0000   \n",
      "1  File_2            0.6760               0.1249     0.0633   \n",
      "2  File_3            0.7103               0.3176     0.0000   \n",
      "\n",
      "   File_Lifecycle_Stage  Modification_Frequency  File_Age Storage_Tier  \\\n",
      "0                0.0000                  0.7786    0.2631          Hot   \n",
      "1                0.4262                  0.1340    0.7871         Warm   \n",
      "2                0.0000                  0.1646    0.1934         Warm   \n",
      "\n",
      "   Storage_Tier_Encoded  \n",
      "0                     2  \n",
      "1                     1  \n",
      "2                     1  \n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"preprocessed-train-file-metadata.csv\") \n",
    "\n",
    "df.head(n=5)\n",
    "\n",
    "df.columns.unique() \n",
    "\n",
    "print(df[\"Storage_Tier\"].dtype)  \n",
    "\n",
    "tier_mapping = { \"Hot\" : 2 , \"Warm\" : 1 , \"Cold\" : 0 }\n",
    "\n",
    "df[\"Storage_Tier_Encoded\"] = df[\"Storage_Tier\"].map(tier_mapping) \n",
    "output_file = (\"preprocessed-train-file-metadata.csv\" )\n",
    "df.to_csv(output_file, index=False) \n",
    "\n",
    "print(df.head(n=3))\n",
    "\n",
    "print(df[\"Storage_Tier_Encoded\"].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used ordinal coding becuase the value of storage tier does matter to train the model\n",
    "\n",
    "hot > warm > cold \n",
    "\n",
    "2 > 1 > 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering & Class Imbalance \n",
    "\n",
    "will drop the storage tier  string column , obvious reason \n",
    "\n",
    "try to deteremine if the target variable : \" storage_tier_encoded \" normal distribution, check for tight edge cases that will imporve the model for boundary cases: if this is lacking then will manually add more rows \n",
    "\n",
    "check if there is a class imbalance for the storage tier to avoid the model overfitting on a certain tier and having a bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Storage_Tier\", axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find z-score to deteremine if a row is an outlier, this test is usually run on columns for which the values are continouns. check for z-score for access_frequency \n",
    "z  = x - mean / standard_deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Access_Frequency</th>\n",
       "      <th>Frequnecy_of_Access</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>File_Lifecycle_Stage</th>\n",
       "      <th>Modification_Frequency</th>\n",
       "      <th>File_Age</th>\n",
       "      <th>Storage_Tier_Encoded</th>\n",
       "      <th>Z_Score_Access_Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Access_Frequency, Frequnecy_of_Access, File_Size, File_Lifecycle_Stage, Modification_Frequency, File_Age, Storage_Tier_Encoded, Z_Score_Access_Frequency]\n",
       "Index: []"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = df[\"Access_Frequency\"].mean() \n",
    "stand_deviation = df[\"Access_Frequency\"].std() \n",
    "\n",
    "df[\"Z_Score_Access_Frequency\"] = round((df[\"Access_Frequency\"] - mean ) / stand_deviation , 4 ) \n",
    "\n",
    "outliers = df[abs(df[\"Z_Score_Access_Frequency\"]) > 3 ] \n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for class imblanace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of training rows')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "col_count = df[\"Storage_Tier_Encoded\"].value_counts() \n",
    "\n",
    "col_count.plot(kind='bar', color = 'blue')\n",
    "plt.title(\"Distributon of Storage Tiers\") \n",
    "plt.xlabel(\"Storage Tier\") \n",
    "plt.ylabel(\"Number of training rows\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly, the target column is heavely skewed in the favour the warm storage (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage_Tier_Encoded\n",
      "1    1495\n",
      "0     266\n",
      "2     239\n",
      "Name: count, dtype: int64\n",
      "Storage_Tier_Encoded\n",
      "1    74.75\n",
      "0    13.30\n",
      "2    11.95\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df[\"Storage_Tier_Encoded\"].value_counts() \n",
    "print(class_counts)\n",
    "\n",
    "class_percentage = df[\"Storage_Tier_Encoded\"].value_counts(normalize=True)  * 100 \n",
    "print(class_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will use SMOTE (synthetic minority over-sampling technique) before training the models, to handle the class imbalance by generating synthetic samples for the minority classes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # multinomal \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "import ipywidgets as widgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop('File_ID',axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Access_Frequency  Frequnecy_of_Access  File_Size  File_Lifecycle_Stage  \\\n",
      "0            0.5890               0.8167     0.0000                0.0000   \n",
      "1            0.6760               0.1249     0.0633                0.4262   \n",
      "2            0.7103               0.3176     0.0000                0.0000   \n",
      "3            0.0681               0.5738     0.0000                0.0000   \n",
      "4            0.5492               0.7808     0.0000                0.0000   \n",
      "\n",
      "   Modification_Frequency  File_Age  Storage_Tier_Encoded  \\\n",
      "0                  0.7786    0.2631                     2   \n",
      "1                  0.1340    0.7871                     1   \n",
      "2                  0.1646    0.1934                     1   \n",
      "3                  0.2712    0.2405                     0   \n",
      "4                  0.3916    0.3551                     1   \n",
      "\n",
      "   Z_Score_Access_Frequency  \n",
      "0                    0.6893  \n",
      "1                    1.0305  \n",
      "2                    1.1650  \n",
      "3                   -1.3536  \n",
      "4                    0.5332  \n",
      "Counter({1: 1192, 0: 214, 2: 194})\n",
      "Counter({1: 1192, 0: 1192, 2: 1192})\n",
      "Training examples: 3576\n",
      "Training labels: 3576\n",
      "Test examples:400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head(n=5))\n",
    "X = df.drop('Storage_Tier_Encoded', axis = 1)\n",
    "Y = df[\"Storage_Tier_Encoded\"] \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8, test_size = 0.2) \n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_SMOTE,Y_train_SMOTE = smote.fit_resample(X_train, Y_train) \n",
    "\n",
    "print(Counter(Y_train))\n",
    "print(Counter(Y_train_SMOTE)) \n",
    "np.random.seed(42)  \n",
    "print(\"Training examples: {}\".format(X_train_SMOTE.shape[0])) \n",
    "print(\"Training labels: {}\".format(Y_train_SMOTE.shape[0])) \n",
    "print(\"Test examples:{}\".format(X_test.shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the training data is balanced and thus should avoid and bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logisitc Regresion Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomail_LR_model = LogisticRegression(multi_class='multinomial')\n",
    "multinomail_LR_model.fit(X_train_SMOTE, Y_train_SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the Multinomal Logisitric Regression Model: 87.5%\n",
      "Classification Report for Multinomail Logistic Regression model:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79        52\n",
      "           1       1.00      0.83      0.91       303\n",
      "           2       0.66      1.00      0.80        45\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.77      0.94      0.83       400\n",
      "weighted avg       0.92      0.88      0.88       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict = multinomail_LR_model.predict(X_test) \n",
    "multi_LR_model_accuracy = accuracy_score(Y_test, predict) * 100 \n",
    "\n",
    "print(f\"Accuracy Score of the Multinomal Logisitric Regression Model: {multi_LR_model_accuracy}%\")\n",
    "# f1_score_LR_model = round(f1_score(Y_test, predict, average='weighted'),4) * 100\n",
    "\n",
    "# print(f\"The F1-Score is {f1_score_LR_model}%\") \n",
    "\n",
    "# print(\"\\nConfusion Matrix\", confusion_matrix(Y_test, predict)) \n",
    "print(\"Classification Report for Multinomail Logistic Regression model:\\n \", classification_report(Y_test, predict)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the multinomal logistic regression model preforming really well, I will try to train some other models like KNN, Decision Tree, Random Forrest, and a Gradient Boosting Model because each of them bring their own strengths for a classification task. At the end, I can summarize the models to deteremine which one worked the best given the dataset and then deploy that model as RESTAPI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors (KNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 5) \n",
    "knn_model.fit(X_train_SMOTE, Y_train_SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN model: 84.25%\n",
      "Classification Report of KNN model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76        52\n",
      "           1       0.98      0.81      0.89       303\n",
      "           2       0.59      0.98      0.73        45\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.74      0.91      0.79       400\n",
      "weighted avg       0.89      0.84      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = knn_model.predict(X_test) \n",
    "accuracy = accuracy_score(Y_test, predict) * 100 \n",
    "class_report = classification_report(Y_test,predict) \n",
    "\n",
    "print(f\"Accuracy of KNN model: {accuracy}%\") \n",
    "print(f\"Classification Report of KNN model:\\n {class_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train_SMOTE, Y_train_SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Model: 86.5%\n",
      "Classification Report of Decision Tree Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79        52\n",
      "           1       0.93      0.89      0.91       303\n",
      "           2       0.62      0.78      0.69        45\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.77      0.82      0.80       400\n",
      "weighted avg       0.87      0.86      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = tree_model.predict(X_test) \n",
    "accuracy = accuracy_score(Y_test, predict) * 100 \n",
    "class_report = classification_report(Y_test, predict)\n",
    "\n",
    "print(f\"Accuracy of Decision Tree Model: {accuracy}%\")\n",
    "print(f\"Classification Report of Decision Tree Model:\\n {class_report}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rforest_model = RandomForestClassifier(n_estimators=100) \n",
    "Rforest_model.fit(X_train_SMOTE,Y_train_SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuract Score of Random Forrest Model: 90.25%\n",
      "Classification Report of Random Forrest Molde:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        52\n",
      "           1       0.94      0.93      0.94       303\n",
      "           2       0.78      0.84      0.81        45\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.84      0.86      0.85       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = Rforest_model.predict(X_test) \n",
    "accuracy = accuracy_score(Y_test, predict) * 100 \n",
    "\n",
    "class_report = classification_report(Y_test, predict) \n",
    "\n",
    "print(f\"Accuract Score of Random Forrest Model: {accuracy}%\") \n",
    "print(f\"Classification Report of Random Forrest Molde:\\n {class_report}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier(eval_metric = 'mlogloss', random_state= 42) \n",
    "xgboost_model.fit(X_train_SMOTE, Y_train_SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score XGBoost Model: 92.5%\n",
      "Classification Report XGBoost Model: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85        52\n",
      "           1       0.96      0.94      0.95       303\n",
      "           2       0.78      0.93      0.85        45\n",
      "\n",
      "    accuracy                           0.93       400\n",
      "   macro avg       0.87      0.90      0.88       400\n",
      "weighted avg       0.93      0.93      0.93       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = xgboost_model.predict(X_test) \n",
    "accuracy = accuracy_score(Y_test, predict) * 100 \n",
    "class_report = classification_report(Y_test, predict) \n",
    "\n",
    "print(f\"Accuracy Score XGBoost Model: {accuracy}%\") \n",
    "print(f\"Classification Report XGBoost Model: \\n {class_report}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary of Basic Models</h3>\n",
    "\n",
    "<br>\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th>Model Type</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th> Weighted F1-Score Avg</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Logistic Regression</td>\n",
    "        <td>87.5%</td>\n",
    "        <td>0.88</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>K-nearest neighbors </td>\n",
    "        <td>84.25%</td>\n",
    "        <td>0.85</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Decision Tree</td>\n",
    "        <td>86.5%</td>\n",
    "        <td>0.87</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Random Forest</td>\n",
    "        <td>91.0%</td>\n",
    "        <td>0.91</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>XGBoost</td>\n",
    "        <td>92.5%</td>\n",
    "        <td>0.93</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why did random forest and XGBoost work so well on this dataset? \n",
    "\n",
    "Random Forest uses multiple decision trees ( so it make sense why it outperformed deciion tree) and then averages out the predictions of the trees to avoid overfitting, and in addtion to using SMOTE for the class imbalance random forest inherenrlty balances the majority and minority classes. \n",
    "\n",
    "All in all both methods are ensemble learning models, and the fact that the logisitc regression and decision tree model have strong accuracy score it makes intutitve sense that the models that use it as weak learners creative a stronger overall model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4) Model Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the XGBoost model has the most accurate model and the closest weighted f1_score avg to 1, it is safe to use this model to classify the storage tier of new files that follow the same csv/json? schema as the datset used to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"../xgboost-model/xgboost_model.pkl\",\"wb\") as file: \n",
    "    pickle.dump(xgboost_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
